prompt: gemma
vllm_args:
  model_args:
    model: output/gemma-2b-it-unifie_dpo_sft_0.05_0.5_lr_1e-6_epoch_1_et_lr_2e-5_epoch_3
    dtype: float16
    tensor_parallel_size: 1
    trust_remote_code: true
  sampling_params:
    temperature: 0
    max_tokens: 20
hf_args:
  model_args:
    model: google/gemma-2b-it
    dtype: float16
