local_rank = None


def set_local_rank(rank):
    global local_rank
    local_rank = rank


def rank0_print(*args):

    if local_rank == 0:
        print(*args)


def create_prompt_et(model_type):
    instruction = ""

    if model_type == "vicuna":
        instruction = """A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.USER: {question_body} ASSISTANT: {answer1_body}</s>You are a helpful assistant in evaluating the quality of the outputs for a given instruction. Your goal is to select the best output for the given instruction.USER: The output given by the assistant above is called Output (a), and the output below is Output (b).
# Output (b):
{answer2_body}

Select the Output (a) or Output (b) that is better for the given instruction. The two outputs are generated by two different AI chatbots respectively.

Here are some rules of the evaluation:
(1) You should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc.
(2) Outputs should NOT contain more/less than what the instruction asks for, as such outputs do NOT precisely execute the instruction.
(3) You should avoid any potential bias and your judgment should be as objective as possible. For example, the order in which the outputs were presented should NOT affect your judgment, as Output (a) and Output (b) are **equally likely** to be the better.

Do NOT provide any explanation for your choice.
Do NOT say both / neither are good.
You should answer using ONLY "Output (a)" or "Output (b)". Do NOT output any other words.

# Which is better, Output (a) or Output (b)? Your response should be either "Output (a)" or "Output (b)": ASSISTANT:"""

    elif model_type == "llama2":
        instruction = """<INST> {question_body} </INST>{answer1_body}</s><s><INST> <<SYS>>
You are a helpful assistant in evaluating the quality of the outputs for a given instruction. Your goal is to select the best output for the given instruction.
<</SYS>>
The output given by the assistant above is called Output (a), and the output below is Output (b).
# Output (b):
{answer2_body}

Select the Output (a) or Output (b) that is better for the given instruction. The two outputs are generated by two different AI chatbots respectively.

Here are some rules of the evaluation:
(1) You should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc.
(2) Outputs should NOT contain more/less than what the instruction asks for, as such outputs do NOT precisely execute the instruction.
(3) You should avoid any potential bias and your judgment should be as objective as possible. For example, the order in which the outputs were presented should NOT affect your judgment, as Output (a) and Output (b) are **equally likely** to be the better.

Do NOT provide any explanation for your choice.
Do NOT say both / neither are good.
You should answer using ONLY "Output (a)" or "Output (b)". Do NOT output any other words.

# Which is better, Output (a) or Output (b)? Your response should be either "Output (a)" or "Output (b)": </INST>"""

    return instruction


def create_prompt_sft(model_type):
    instruction = ""

    if model_type == "vicuna":
        instruction = """A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.USER: {question_body} ASSISTANT:"""

    elif model_type == "llama2":
        instruction = """<INST> {question_body} </INST>"""

    return instruction


def format_instruction_sft(instruction, example):
    prompt = instruction.format(question_body=example["instruction"])
    return prompt


def format_instruction_et(instruction, example):
    prompt = instruction.format(question_body=example["instruction"],
                                answer1_body=example["chosen"],
                                answer2_body=example["rejected"])
    return prompt
