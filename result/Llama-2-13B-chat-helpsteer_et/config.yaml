prompt: llmbar
vllm_args:
  model_args:
    model: /H1/zhouhongli/JudgePO/LLaMA-Factory/output/Llama-2-13B-chat-helpsteer_et
    tensor_parallel_size: 1
    trust_remote_code: true
  sampling_params:
    temperature: 0
    max_tokens: 20
hf_args:
  model_args:
    model: meta-llama/Llama-2-13b-chat
    dtype: float16
